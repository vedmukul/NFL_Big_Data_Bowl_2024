{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526f5b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:28.407707Z",
     "iopub.status.busy": "2023-12-22T23:31:28.407082Z",
     "iopub.status.idle": "2023-12-22T23:31:30.935726Z",
     "shell.execute_reply": "2023-12-22T23:31:30.934552Z"
    },
    "papermill": {
     "duration": 2.549013,
     "end_time": "2023-12-22T23:31:30.938813",
     "exception": false,
     "start_time": "2023-12-22T23:31:28.389800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the packages\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, classification_report, roc_curve, auc, accuracy_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f90d68",
   "metadata": {
    "papermill": {
     "duration": 0.016024,
     "end_time": "2023-12-22T23:31:30.971102",
     "exception": false,
     "start_time": "2023-12-22T23:31:30.955078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Integration and Cleaning\n",
    "Merging datasets from four different data sources (games, players, plays, and tackles) into a comprehensive dataset, ensuring data quality and consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cb06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:31.004999Z",
     "iopub.status.busy": "2023-12-22T23:31:31.004266Z",
     "iopub.status.idle": "2023-12-22T23:31:31.206125Z",
     "shell.execute_reply": "2023-12-22T23:31:31.204882Z"
    },
    "papermill": {
     "duration": 0.222426,
     "end_time": "2023-12-22T23:31:31.209394",
     "exception": false,
     "start_time": "2023-12-22T23:31:30.986968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "games_df = pd.read_csv(\"/Users/ved/Downloads/nfl-big-data-bowl-2024/games.csv\")\n",
    "players_df = pd.read_csv(\"/Users/ved/Downloads/nfl-big-data-bowl-2024/players.csv\")\n",
    "plays_df = pd.read_csv(\"/Users/ved/Downloads/nfl-big-data-bowl-2024/plays.csv\")\n",
    "tackles_df = pd.read_csv(\"/Users/ved/Downloads/nfl-big-data-bowl-2024/tackles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2550251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:31.243264Z",
     "iopub.status.busy": "2023-12-22T23:31:31.242795Z",
     "iopub.status.idle": "2023-12-22T23:31:31.283210Z",
     "shell.execute_reply": "2023-12-22T23:31:31.282034Z"
    },
    "papermill": {
     "duration": 0.060323,
     "end_time": "2023-12-22T23:31:31.285869",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.225546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preview the datasets\n",
    "games_df.head(5), players_df.head(5), plays_df.head(5), tackles_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62b1e2",
   "metadata": {
    "papermill": {
     "duration": 0.015614,
     "end_time": "2023-12-22T23:31:31.317490",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.301876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Insights from datasets:**\n",
    "* Players data: include players’ heights, weights, and position may \n",
    "* Play data: column ‘down’ and 'yardsToGo’ provide crucial information about the ongoing play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb225f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:31.351123Z",
     "iopub.status.busy": "2023-12-22T23:31:31.350630Z",
     "iopub.status.idle": "2023-12-22T23:31:31.391170Z",
     "shell.execute_reply": "2023-12-22T23:31:31.390316Z"
    },
    "papermill": {
     "duration": 0.060074,
     "end_time": "2023-12-22T23:31:31.393451",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.333377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tackles_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88658692",
   "metadata": {
    "papermill": {
     "duration": 0.016471,
     "end_time": "2023-12-22T23:31:31.426795",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.410324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From the above table, we can see that the success tackle rate is around 56.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba288c",
   "metadata": {
    "papermill": {
     "duration": 0.1045,
     "end_time": "2023-12-22T23:31:31.547428",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.442928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "To understand the factors that might influence the success tackle rate, we would further perform a more detailed analysis by considering various aspects of the data.\n",
    "\n",
    "First, I would start with merging the four datasets together using 'nflId', 'gameId', and 'playId'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab9721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:31.582416Z",
     "iopub.status.busy": "2023-12-22T23:31:31.581636Z",
     "iopub.status.idle": "2023-12-22T23:31:31.680865Z",
     "shell.execute_reply": "2023-12-22T23:31:31.680015Z"
    },
    "papermill": {
     "duration": 0.119946,
     "end_time": "2023-12-22T23:31:31.683729",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.563783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge tackles data with player data\n",
    "combined_df_1 = pd.merge(tackles_df, players_df, on = 'nflId')\n",
    "\n",
    "# Then merge with play data\n",
    "combined_df_2 = pd.merge(combined_df_1, plays_df, on = ['gameId', 'playId'])\n",
    "\n",
    "# Further merge with games data\n",
    "data = pd.merge(combined_df_2, games_df, on = 'gameId')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab835b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:31.720536Z",
     "iopub.status.busy": "2023-12-22T23:31:31.719548Z",
     "iopub.status.idle": "2023-12-22T23:31:31.755893Z",
     "shell.execute_reply": "2023-12-22T23:31:31.754921Z"
    },
    "papermill": {
     "duration": 0.057794,
     "end_time": "2023-12-22T23:31:31.758740",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.700946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert height to numerical numbers\n",
    "def height_to_inches(height_str):\n",
    "    if isinstance(height_str, str):\n",
    "        parts = height_str.split('-')\n",
    "        if len(parts) == 2:\n",
    "            feet, inches = int(parts[0]), int(parts[1])\n",
    "            return feet * 12 + inches\n",
    "    return height_str  # if not string, return as is\n",
    "\n",
    "# Apply the conversion to the 'height' column\n",
    "data['height'] = data['height'].apply(height_to_inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533af26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:31.795448Z",
     "iopub.status.busy": "2023-12-22T23:31:31.794737Z",
     "iopub.status.idle": "2023-12-22T23:31:31.919873Z",
     "shell.execute_reply": "2023-12-22T23:31:31.918516Z"
    },
    "papermill": {
     "duration": 0.146969,
     "end_time": "2023-12-22T23:31:31.923001",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.776032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb4309b",
   "metadata": {
    "papermill": {
     "duration": 0.017416,
     "end_time": "2023-12-22T23:31:31.958933",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.941517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Investigate the distribution of tackles across various attributes and identify patterns and correlations. Techniques like heatmaps and histograms are used for this analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695a469",
   "metadata": {
    "papermill": {
     "duration": 0.017732,
     "end_time": "2023-12-22T23:31:31.994051",
     "exception": false,
     "start_time": "2023-12-22T23:31:31.976319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Correlation Matrix Heatmap\n",
    "I started with looking at the distribution of tackles across different player attributes, play characteristics, and game context:\n",
    "* player attributes (ex: height, weight, position)\n",
    "* play characteristics (ex: down, yards to go)\n",
    "* game context (ex: score, quarter, assist, forced Fumble, pff_missedTackle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052301a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:32.031439Z",
     "iopub.status.busy": "2023-12-22T23:31:32.030600Z",
     "iopub.status.idle": "2023-12-22T23:31:32.767928Z",
     "shell.execute_reply": "2023-12-22T23:31:32.766515Z"
    },
    "papermill": {
     "duration": 0.759608,
     "end_time": "2023-12-22T23:31:32.771116",
     "exception": false,
     "start_time": "2023-12-22T23:31:32.011508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting relevant features for analysis\n",
    "features = ['tackle', 'weight', 'height', 'down', 'position', 'yardsToGo', 'yardlineNumber', 'assist', 'forcedFumble', 'pff_missedTackle']\n",
    "eda_df = data[features]\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "dummy_columns = pd.get_dummies(eda_df['position'])\n",
    "eda_df = pd.concat([eda_df, dummy_columns], axis=1)\n",
    "\n",
    "# Drop the original 'position' column as it's now represented by dummies\n",
    "eda_df.drop('position', axis=1, inplace=True)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = eda_df.corr()\n",
    "\n",
    "# Generate a heatmap to visualize the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965783c",
   "metadata": {
    "papermill": {
     "duration": 0.018238,
     "end_time": "2023-12-22T23:31:32.808199",
     "exception": false,
     "start_time": "2023-12-22T23:31:32.789961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The heatmap above illustrates the correlation coefficients between different features in our dataset. Darker red squares indicate a stronger positive correlation, while darker blue squares signify a stronger negative correlation. The diagonal line shows a perfect positive correlation (correlation coefficient of 1) where each feature correlates with itself.\n",
    "\n",
    "Notably, the features `assist` and `forcedFumble` exhibit a positive correlation with `tackle`, suggesting a relationship between these variables and successful tackles. The player positions, represented as dummy variables, also provide interesting insights; for example, `position_CB` correlates with `pff_missedTackle`, which may reflect the involvement of cornerbacks in plays with missed tackles.\n",
    "\n",
    "Variables with minimal correlation (light-colored squares) will be considered carefully for their relevance in predictive modeling. It's important to remember that correlation does not equal causation, and this heatmap solely reflects linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d55c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:32.847766Z",
     "iopub.status.busy": "2023-12-22T23:31:32.847255Z",
     "iopub.status.idle": "2023-12-22T23:31:33.352707Z",
     "shell.execute_reply": "2023-12-22T23:31:33.351487Z"
    },
    "papermill": {
     "duration": 0.528696,
     "end_time": "2023-12-22T23:31:33.355619",
     "exception": false,
     "start_time": "2023-12-22T23:31:32.826923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = eda_df.corr()\n",
    "\n",
    "# Sort the correlations with 'tackle'\n",
    "sorted_correlation_with_tackle = correlation_matrix['tackle'].sort_values(key = abs, ascending = False)\n",
    "\n",
    "# Exclude the 'tackle' variable itself to avoid a self-correlation of 1\n",
    "sorted_correlation_with_tackle = sorted_correlation_with_tackle[sorted_correlation_with_tackle.index != 'tackle']\n",
    "\n",
    "# Now, visualize this sorted correlation with a bar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=sorted_correlation_with_tackle.values, y=sorted_correlation_with_tackle.index)\n",
    "plt.title('Correlation with Tackle Success')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0e070",
   "metadata": {
    "papermill": {
     "duration": 0.019179,
     "end_time": "2023-12-22T23:31:33.434906",
     "exception": false,
     "start_time": "2023-12-22T23:31:33.415727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Distribution of Tackles by Player\n",
    "Next, I wanted to look at the performance and frequency of tackles by each player.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e868d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:33.476438Z",
     "iopub.status.busy": "2023-12-22T23:31:33.475958Z",
     "iopub.status.idle": "2023-12-22T23:31:33.790907Z",
     "shell.execute_reply": "2023-12-22T23:31:33.789651Z"
    },
    "papermill": {
     "duration": 0.339202,
     "end_time": "2023-12-22T23:31:33.793839",
     "exception": false,
     "start_time": "2023-12-22T23:31:33.454637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tackle_players = data.groupby(['nflId'])['tackle'].agg('sum')\n",
    "\n",
    "# Creating a DataFrame by passing a dictionary\n",
    "frame = {'nfl_id': tackle_players.index, 'tackles': tackle_players}\n",
    "agg_data = pd.DataFrame(frame).reset_index()\n",
    "agg_data = agg_data.drop(columns=['nfl_id'], axis=1)\n",
    "\n",
    "# Plotting using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(agg_data['tackles'], bins=20, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Tackles by Players')\n",
    "plt.xlabel('Tackles')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966da73",
   "metadata": {
    "papermill": {
     "duration": 0.019284,
     "end_time": "2023-12-22T23:31:33.872548",
     "exception": false,
     "start_time": "2023-12-22T23:31:33.853264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Distribution of tackles by player height and weight\n",
    "Then, I started looking at players’ heights and weights to find patterns related to the occurrence of successful tackles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685eaac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:33.914750Z",
     "iopub.status.busy": "2023-12-22T23:31:33.914162Z",
     "iopub.status.idle": "2023-12-22T23:31:35.438867Z",
     "shell.execute_reply": "2023-12-22T23:31:35.437483Z"
    },
    "papermill": {
     "duration": 1.550131,
     "end_time": "2023-12-22T23:31:35.442606",
     "exception": false,
     "start_time": "2023-12-22T23:31:33.892475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data[data['tackle'] == 1]['height'], kde=True, color='blue', label='Successful Tackles')\n",
    "sns.histplot(data[data['tackle'] == 0]['height'], kde=True, color='red', label='Unsuccessful Tackles')\n",
    "plt.title('Distribution of Tackles by Player Height')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(data[data['tackle'] == 1]['weight'], kde=True, color='blue', label='Successful Tackles')\n",
    "sns.histplot(data[data['tackle'] == 0]['weight'], kde=True, color='red', label='Unsuccessful Tackles')\n",
    "plt.title('Distribution of Tackles by Player Weight')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fe04a",
   "metadata": {
    "papermill": {
     "duration": 0.021295,
     "end_time": "2023-12-22T23:31:35.528508",
     "exception": false,
     "start_time": "2023-12-22T23:31:35.507213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "After EDA, I created new features like player BMI and interaction terms to capture complex relationships within the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1132f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:35.617835Z",
     "iopub.status.busy": "2023-12-22T23:31:35.617357Z",
     "iopub.status.idle": "2023-12-22T23:31:35.972703Z",
     "shell.execute_reply": "2023-12-22T23:31:35.971456Z"
    },
    "papermill": {
     "duration": 0.381436,
     "end_time": "2023-12-22T23:31:35.975291",
     "exception": false,
     "start_time": "2023-12-22T23:31:35.593855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature 1: Interaction term between 'down' and 'yardsToGo'\n",
    "data['down_yards_interaction'] = data['down'] * data['yardsToGo']\n",
    "\n",
    "# Feature 2: Body Mass Index (BMI)\n",
    "def calculate_bmi(weight, height_in_inches):\n",
    "    # BMI formula: 703 * weight in pounds / (height in inches)^2\n",
    "    return 703 * weight / (height_in_inches ** 2)\n",
    "data['player_bmi'] = data.apply(lambda row: calculate_bmi(row['weight'], row['height']), axis=1)\n",
    "\n",
    "feature_data = data[['down_yards_interaction', 'player_bmi', 'quarter', 'assist', 'forcedFumble', 'tackle']]\n",
    "feature_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7dbdb",
   "metadata": {
    "papermill": {
     "duration": 0.021645,
     "end_time": "2023-12-22T23:31:36.018983",
     "exception": false,
     "start_time": "2023-12-22T23:31:35.997338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8117221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:36.066176Z",
     "iopub.status.busy": "2023-12-22T23:31:36.065217Z",
     "iopub.status.idle": "2023-12-22T23:31:36.098818Z",
     "shell.execute_reply": "2023-12-22T23:31:36.097678Z"
    },
    "papermill": {
     "duration": 0.060212,
     "end_time": "2023-12-22T23:31:36.101697",
     "exception": false,
     "start_time": "2023-12-22T23:31:36.041485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation, and test sets\n",
    "train, test = train_test_split(feature_data, test_size=0.4, random_state=42)\n",
    "val, test = train_test_split(test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Apply get_dummies to each split separately\n",
    "X_train = pd.get_dummies(train.drop('tackle', axis=1), drop_first=True)\n",
    "y_train = train['tackle']\n",
    "\n",
    "X_val = pd.get_dummies(val.drop('tackle', axis=1), drop_first=True)\n",
    "y_val = val['tackle']\n",
    "\n",
    "X_test = pd.get_dummies(test.drop('tackle', axis=1), drop_first=True)\n",
    "y_test = test['tackle']\n",
    "\n",
    "# Standardize the numerical features\n",
    "# Note: Only standardize numerical columns. For simplicity, I'm assuming all columns are now either numerical or one-hot encoded\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Now, the dataset should be ready for training and evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5009957",
   "metadata": {
    "papermill": {
     "duration": 0.021748,
     "end_time": "2023-12-22T23:31:36.190482",
     "exception": false,
     "start_time": "2023-12-22T23:31:36.168734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Support Vector Machines (SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a90f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:36.237549Z",
     "iopub.status.busy": "2023-12-22T23:31:36.236364Z",
     "iopub.status.idle": "2023-12-22T23:31:37.161153Z",
     "shell.execute_reply": "2023-12-22T23:31:37.159254Z"
    },
    "papermill": {
     "duration": 0.951438,
     "end_time": "2023-12-22T23:31:37.164078",
     "exception": false,
     "start_time": "2023-12-22T23:31:36.212640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m = y.size\n",
    "        if m <= self.min_samples_split:\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes)]\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "        for idx in range(self.n_features):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * self.n_classes\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_samples_split=2, n_samples=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_samples = n_samples\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            if self.n_samples is None:\n",
    "                X_subset, y_subset = X, y\n",
    "            else:\n",
    "                indices = np.random.choice(len(X), size=self.n_samples, replace=True)\n",
    "                X_subset, y_subset = X[indices], y[indices]\n",
    "            tree.fit(X_subset, y_subset)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(X), len(self.trees)))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X)\n",
    "        predictions = np.round(predictions).astype(int)  # Round predictions to the nearest integer\n",
    "        return np.array([np.argmax(np.bincount(predictions[i])) for i in range(len(X))])\n",
    "\n",
    "# Load and prepare your data (X_train, y_train, X_test, y_test)\n",
    "feature_data = data[['down_yards_interaction', 'player_bmi', 'quarter', 'assist', 'forcedFumble', 'tackle']]\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "train, test = train_test_split(feature_data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Apply get_dummies to each split separately\n",
    "X_train = pd.get_dummies(train.drop('tackle', axis=1), drop_first=True)\n",
    "y_train = train['tackle'].astype(int)  # Convert y_train to integer\n",
    "\n",
    "X_test = pd.get_dummies(test.drop('tackle', axis=1), drop_first=True)\n",
    "y_test = test['tackle'].astype(int)  # Convert y_test to integer\n",
    "\n",
    "# Standardize the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the RandomForest classifier\n",
    "rf_clf = RandomForest(n_trees=100, max_depth=10, min_samples_split=2, n_samples=None)\n",
    "\n",
    "# Train the model\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Compute the feature importances\n",
    "feature_importances = np.zeros(X_train.shape[1])\n",
    "for tree in rf_clf.trees:\n",
    "    feature_importances += np.zeros(X_train.shape[1])\n",
    "    node = tree.tree\n",
    "    while node.left:\n",
    "        feature_importances[node.feature_index] += node.num_samples\n",
    "        node = node.left if np.sum(node.left.num_samples) > np.sum(node.right.num_samples) else node.right\n",
    "feature_importances /= len(rf_clf.trees)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X_train.shape[1]), feature_importances)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f0618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:37.210940Z",
     "iopub.status.busy": "2023-12-22T23:31:37.209852Z",
     "iopub.status.idle": "2023-12-22T23:31:37.649711Z",
     "shell.execute_reply": "2023-12-22T23:31:37.648423Z"
    },
    "papermill": {
     "duration": 0.466444,
     "end_time": "2023-12-22T23:31:37.652837",
     "exception": false,
     "start_time": "2023-12-22T23:31:37.186393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "198711c5",
   "metadata": {
    "papermill": {
     "duration": 0.02229,
     "end_time": "2023-12-22T23:31:37.743429",
     "exception": false,
     "start_time": "2023-12-22T23:31:37.721139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9968e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:37.791842Z",
     "iopub.status.busy": "2023-12-22T23:31:37.790582Z",
     "iopub.status.idle": "2023-12-22T23:31:38.334053Z",
     "shell.execute_reply": "2023-12-22T23:31:38.332787Z"
    },
    "papermill": {
     "duration": 0.570755,
     "end_time": "2023-12-22T23:31:38.336798",
     "exception": false,
     "start_time": "2023-12-22T23:31:37.766043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(fit_intercept=True, max_iter=1000).fit(X_train,y_train)\n",
    "\n",
    "logistic_pred_test = logistic_model.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, logistic_pred_test[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6dac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:38.387638Z",
     "iopub.status.busy": "2023-12-22T23:31:38.386727Z",
     "iopub.status.idle": "2023-12-22T23:31:38.397308Z",
     "shell.execute_reply": "2023-12-22T23:31:38.396337Z"
    },
    "papermill": {
     "duration": 0.039256,
     "end_time": "2023-12-22T23:31:38.399896",
     "exception": false,
     "start_time": "2023-12-22T23:31:38.360640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, (logistic_pred_test[:,1] > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e7a16",
   "metadata": {
    "papermill": {
     "duration": 0.023503,
     "end_time": "2023-12-22T23:31:38.447674",
     "exception": false,
     "start_time": "2023-12-22T23:31:38.424171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Accuracy: 0.878/ AUC: 0.87\n",
    "* Given our binary outcome (successful or unsuccessful tackle), I adopt logistic regression to predict the probability of a tackle’s success based on our selected input features. An AUC of 0.87 shows a high level of model performance, with the model having a good measure of separability and being able to distinguish between success and failure tackles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c695891",
   "metadata": {
    "papermill": {
     "duration": 0.023418,
     "end_time": "2023-12-22T23:31:38.494663",
     "exception": false,
     "start_time": "2023-12-22T23:31:38.471245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a126d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:38.545721Z",
     "iopub.status.busy": "2023-12-22T23:31:38.544411Z",
     "iopub.status.idle": "2023-12-22T23:31:51.119272Z",
     "shell.execute_reply": "2023-12-22T23:31:51.117502Z"
    },
    "papermill": {
     "duration": 12.60404,
     "end_time": "2023-12-22T23:31:51.122847",
     "exception": false,
     "start_time": "2023-12-22T23:31:38.518807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m = y.size\n",
    "        if m <= self.min_samples_split:\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes)]\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "        for idx in range(self.n_features):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * self.n_classes\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_samples_split=2, n_samples=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_samples = n_samples\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            if self.n_samples is None:\n",
    "                X_subset, y_subset = X, y\n",
    "            else:\n",
    "                indices = np.random.choice(len(X), size=self.n_samples, replace=True)\n",
    "                X_subset, y_subset = X[indices], y[indices]\n",
    "            tree.fit(X_subset, y_subset)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(X), len(self.trees)))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X)\n",
    "        predictions = np.round(predictions).astype(int)  # Round predictions to the nearest integer\n",
    "        return np.array([np.argmax(np.bincount(predictions[i])) for i in range(len(X))])\n",
    "\n",
    "# Load and prepare your data (X_train, y_train, X_test, y_test)\n",
    "feature_data = data[['down_yards_interaction', 'player_bmi', 'quarter', 'assist', 'forcedFumble', 'tackle']]\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "train, test = train_test_split(feature_data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Apply get_dummies to each split separately\n",
    "X_train = pd.get_dummies(train.drop('tackle', axis=1), drop_first=True)\n",
    "y_train = train['tackle'].astype(int)  # Convert y_train to integer\n",
    "\n",
    "X_test = pd.get_dummies(test.drop('tackle', axis=1), drop_first=True)\n",
    "y_test = test['tackle'].astype(int)  # Convert y_test to integer\n",
    "\n",
    "# Standardize the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the RandomForest classifier\n",
    "rf_clf = RandomForest(n_trees=100, max_depth=10, min_samples_split=2, n_samples=None)\n",
    "\n",
    "# Train the model\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Compute the feature importances\n",
    "feature_importances = np.zeros(X_train.shape[1])\n",
    "for tree in rf_clf.trees:\n",
    "    feature_importances += np.zeros(X_train.shape[1])\n",
    "    node = tree.tree\n",
    "    while node.left:\n",
    "        feature_importances[node.feature_index] += node.num_samples\n",
    "        node = node.left if np.sum(node.left.num_samples) > np.sum(node.right.num_samples) else node.right\n",
    "feature_importances /= len(rf_clf.trees)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X_train.shape[1]), feature_importances)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76802ac4",
   "metadata": {
    "papermill": {
     "duration": 0.025431,
     "end_time": "2023-12-22T23:31:51.767779",
     "exception": false,
     "start_time": "2023-12-22T23:31:51.742348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564d732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:51.821538Z",
     "iopub.status.busy": "2023-12-22T23:31:51.820747Z",
     "iopub.status.idle": "2023-12-22T23:31:51.839219Z",
     "shell.execute_reply": "2023-12-22T23:31:51.838249Z"
    },
    "papermill": {
     "duration": 0.049125,
     "end_time": "2023-12-22T23:31:51.842377",
     "exception": false,
     "start_time": "2023-12-22T23:31:51.793252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function for printing a tree\n",
    "import pydot\n",
    "from io import StringIO\n",
    "from IPython.display import Image\n",
    "def print_tree(estimator, features, class_names=None, filled=True):\n",
    "  tree = estimator\n",
    "  names = features\n",
    "  color = filled\n",
    "  classn = class_names\n",
    "  dot_data = StringIO()\n",
    "  export_graphviz(estimator, out_file=dot_data,feature_names=features,class_names=classn, filled=filled)\n",
    "  graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "  return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be844c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:31:51.896428Z",
     "iopub.status.busy": "2023-12-22T23:31:51.895656Z",
     "iopub.status.idle": "2023-12-22T23:32:34.617342Z",
     "shell.execute_reply": "2023-12-22T23:32:34.614484Z"
    },
    "papermill": {
     "duration": 43.119668,
     "end_time": "2023-12-22T23:32:34.987763",
     "exception": false,
     "start_time": "2023-12-22T23:31:51.868095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tackle_tree = DecisionTreeClassifier(min_samples_split=3,min_impurity_decrease=0.000001)\n",
    "tackle_tree.fit(X_train, y_train)\n",
    "graph, = print_tree(tackle_tree, features= train.drop(columns = ['tackle']).columns)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcad0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:32:35.371366Z",
     "iopub.status.busy": "2023-12-22T23:32:35.370627Z",
     "iopub.status.idle": "2023-12-22T23:32:35.377082Z",
     "shell.execute_reply": "2023-12-22T23:32:35.376245Z"
    },
    "papermill": {
     "duration": 0.19802,
     "end_time": "2023-12-22T23:32:35.379518",
     "exception": false,
     "start_time": "2023-12-22T23:32:35.181498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tackle_tree_preds = tackle_tree.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6941cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T23:32:35.753283Z",
     "iopub.status.busy": "2023-12-22T23:32:35.752525Z",
     "iopub.status.idle": "2023-12-22T23:32:36.063964Z",
     "shell.execute_reply": "2023-12-22T23:32:36.062744Z"
    },
    "papermill": {
     "duration": 0.502067,
     "end_time": "2023-12-22T23:32:36.066813",
     "exception": false,
     "start_time": "2023-12-22T23:32:35.564746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(val['tackle'], tackle_tree_preds[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcafcfb6",
   "metadata": {
    "papermill": {
     "duration": 0.187894,
     "end_time": "2023-12-22T23:32:36.817331",
     "exception": false,
     "start_time": "2023-12-22T23:32:36.629437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Result"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6654553,
     "sourceId": 60305,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 77.894244,
   "end_time": "2023-12-22T23:32:42.431190",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-22T23:31:24.536946",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
